{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Report\n",
    "## Predicting Household Energy Usage\n",
    "### Hunter Adrian  \n",
    "### Brown University  \n",
    "### [GitHub Repository Link](https://github.com/huntera-1/Data1030-Final-Project)\n",
    "### December 15, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Problem Motivation\n",
    "Household energy consumption is a significant contributor to global energy demand and carbon emissions. Accurate predictions of energy usage enable efficient resource management, sustainable energy practices, and waste reduction. With the increase in number of smart devices and sensors, vast datasets capturing energy usage and environmental conditions have become available. This project leverages machine learning techniques to predict household energy consumption, offering a path toward more sustainable living.\n",
    "\n",
    "### Dataset Description\n",
    "The dataset for this project was collected from a household energy monitoring system and contains approximately **20,000 records**. It includes:\n",
    "- **Target Variable**: Appliance energy consumption (Wh).\n",
    "- **Features**: Environmental factors such as temperature, humidity, wind speed, visibility, and pressure.\n",
    "- **Temporal Data**: Timestamp information enabling feature engineering for cyclical and lagged effects.\n",
    "\n",
    "The dataset required extensive preprocessing, including handling missing values, scaling features, and engineering lagged and rolling statistical features to model temporal dependencies.\n",
    "\n",
    "### Previous Work\n",
    "Energy consumption prediction has been studied extensively using statistical and ML approaches. Linear models, such as Ridge regression, are valued for their simplicity and interpretability, while ensemble methods, such as Random Forest, have demonstrated robustness in capturing complex relationships. Recently, XGBoost has shown significant promise for its ability to handle non-linear patterns and interactions. This project builds upon these findings, developing a robust pipeline to model household energy usage effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis focuses on uncovering trends and patterns in energy usage and its relationships with environmental factors.\n",
    "\n",
    "### Energy Consumption Trends\n",
    "Daily energy consumption fluctuates significantly over time, with higher usage during colder months. Peaks align with daily household routines, such as increased evening activity.\n",
    "\n",
    "![Figure 1: Daily Energy Consumption Trends](../figures/daily_energy_trends.png)\n",
    "\n",
    "### Correlation Analysis\n",
    "A correlation heatmap reveals strong relationships between energy consumption and environmental features:\n",
    "- **Outdoor Temperature**: Inversely correlated, reflecting heating demands during colder periods.\n",
    "- **Humidity Levels**: showed a positive relationship in certain areas, which may be linked to systems that control the environment.\n",
    "\n",
    "![Correlation Heatmap](../figures/correlation_heatmap.png)\n",
    "\n",
    "### Distribution of Energy Consumption\n",
    "The histogram shows a right-skewed distribution, with most consumption values clustered at lower ranges and occasional spikes reflecting high-demand periods.\n",
    "\n",
    "![Distribution of Energy Consumption](../figures/histogram_energy_distribution.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "### Splitting Strategy\n",
    "The dataset was divided into three subsets:\n",
    "- **Training Set** (60%): Used to train the models.\n",
    "- **Validation Set** (20%): Used for tuning hyperparameters and selecting the best model.\n",
    "- **Test Set** (20%): Held back for the final evaluation.\n",
    "\n",
    "The split was done chronologically to preserve the time-based structure of the data. This ensures the approach mimics real-world forecasting and avoids data leakage.\n",
    "\n",
    "### Data Preprocessing\n",
    "1. **Feature Engineering**:\n",
    "   - **Lagged Features**: Added `lag_1`, `lag_3`, and `lag_6` to capture dependencies over time.\n",
    "   - **Rolling Statistics**: Smoothed short-term variations with rolling means (`rolling_mean_3`, `rolling_mean_6`) and standard deviations (`rolling_std_3`, `rolling_std_6`).\n",
    "   - **Cyclical Encoding**: Represented `hour` and `day_of_week` as sine and cosine values to account for patterns that repeat over time.\n",
    "2. **Scaling**:\n",
    "   - Standardized numerical features using `StandardScaler` to ensure all features had consistent scales.\n",
    "\n",
    "### Models and Hyperparameter Tuning\n",
    "Three models were trained and optimized using `RandomizedSearchCV`:\n",
    "1. **Ridge Regression**:\n",
    "   - Tuned `alpha` (regularization strength) between 0.1 and 300.\n",
    "2. **Random Forest Regressor**:\n",
    "   - Adjusted `n_estimators` (50, 100, 200) and `max_depth` (10, 20, 50, None).\n",
    "3. **XGBoost Regressor**:\n",
    "   - Tuned `learning_rate` (0.01, 0.05, 0.1), `max_depth` (3, 6, 9), and `n_estimators` (50, 100, 200).\n",
    "\n",
    "### Evaluation Metric\n",
    "The main metric was Root Mean Squared Error (RMSE). RMSE penalizes larger errors more, making it suitable for energy forecasting where large deviations can have significant consequences.\n",
    "\n",
    "### Cross-Validation\n",
    "Time Series Cross-Validation (`TimeSeriesSplit`) with three splits was used during hyperparameter tuning. This method ensures that the validation data always comes after the training data in the timeline, preserving temporal order.\n",
    "\n",
    "### Ethical Considerations\n",
    "- A chronological split ensured that no future data influenced past predictions, reducing the risk of overfitting.\n",
    "- Cross-validation and regularization techniques were applied to build robust and reliable models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results\n",
    "\n",
    "### Model Performance\n",
    "The models were assessed using Root Mean Squared Error (RMSE) and R² on the test set. The results are summarized below:\n",
    "\n",
    "| Model              | Validation RMSE | Test RMSE | Test R²  |\n",
    "|--------------------|-----------------|-----------|----------|\n",
    "| Baseline (Mean)    | —               | 90.4786   | —        |\n",
    "| Ridge Regression   | 43.1295         | 41.2233   | 0.7924   |\n",
    "| Random Forest      | 38.1613         | 40.0705   | 0.8039   |\n",
    "| XGBoost            | 38.0525         | 40.9152   | 0.7955   |\n",
    "\n",
    "The baseline model, which predicts the mean energy consumption for all instances, had an RMSE of **90.4786 Wh**. All three machine learning models significantly outperformed the baseline, highlighting the value of advanced modeling and feature engineering.\n",
    "\n",
    "### Best Performing Model\n",
    "The **Random Forest Regressor** emerged as the best performer with the lowest test RMSE of **40.0705 Wh** and the highest R² of **0.8039**. This indicates its ability to capture the dataset's non-linear patterns and temporal dependencies.\n",
    "\n",
    "The top 10 important features identified by the Random Forest model are displayed in Figure 1. Key features include:\n",
    "- **Outdoor Temperature**: Influences energy use by affecting heating and cooling demand.\n",
    "- **Lagged Features (Lag 1, Lag 3)**: Reflects the dependency of current energy usage on recent trends.\n",
    "- **Rolling Means**: Smoother features that reveal broader patterns in the data.\n",
    "\n",
    "![Figure 1: Top 10 Feature Importances for Random Forest](../figures/xgboost_feature_importance.png)\n",
    "\n",
    "### Model Interpretation\n",
    "The XGBoost model also performed well, with a test RMSE of **40.9152 Wh** and R² of **0.7955**. Figure 2 compares the true and predicted energy consumption values for XGBoost, showing good alignment, which demonstrates the model's ability to generalize effectively to unseen data.\n",
    "\n",
    "![Figure 2: True vs. Predicted Energy Consumption (XGBoost)](../figures/xgboost_true_vs_predicted.png)\n",
    "\n",
    "Residual analysis (Figure 3) indicates minimal bias in XGBoost predictions, with errors centered around zero. A slight over-prediction is noticeable for lower energy usage values.\n",
    "\n",
    "![Figure 3: Residual Plot for XGBoost](../figures/xgboost_residual_plot.png)\n",
    "\n",
    "### Key Observations\n",
    "- Tree-based models, such as Random Forest and XGBoost, outperformed Ridge Regression, underscoring the importance of non-linear modeling for energy forecasting.\n",
    "- Feature engineering, particularly lagged and rolling statistical features, played a key role in enhancing model performance.\n",
    "- The alignment of predictions with actual energy consumption trends validates the modeling approach and highlights its effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlook\n",
    "\n",
    "### Limitations\n",
    "While the models demonstrated strong predictive performance, several limitations were identified:\n",
    "- **Single Household Data**: The dataset is limited to one household, which may restrict the applicability of the models to other households or regions with different energy usage patterns.\n",
    "- **Reliance on Lagged and Rolling Features**: The models depend heavily on these features, which may not fully capture long-term dependencies or seasonal variations in energy usage.\n",
    "- **Feature Collinearity**: Analysis of feature importance revealed potential collinearity among environmental variables, which could obscure the true impact of individual predictors on energy consumption.\n",
    "\n",
    "### Improvements\n",
    "To address these limitations and enhance model performance:\n",
    "- **Expand Dataset**: Collect data from multiple households across diverse regions to improve the generalizability of the models.\n",
    "- **Add Features**: Incorporate additional variables, such as electricity prices and broader weather metrics (e.g., wind speed, solar radiation), to better capture factors influencing energy usage.\n",
    "- **Advanced Temporal Modeling**: Explore more sophisticated models, such as LSTM or Transformer-based architectures, to capture longer-term dependencies and seasonal patterns.\n",
    "\n",
    "### Future Work\n",
    "Future research can focus on several areas to refine and expand this study:\n",
    "- **Interpretability**: Apply interpretability frameworks like SHAP or LIME to provide deeper insights into model predictions and the influence of specific features.\n",
    "- **Real-Time Applications**: Develop a real-time energy monitoring and prediction system based on the trained models to assist households in optimizing energy consumption. This practical application could enhance the utility of the research.\n",
    "- **Out-of-Sample Testing**: Evaluate model performance on unseen data, including different time periods or households, to assess robustness and further validate generalizability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
